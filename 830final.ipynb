{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a061fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Project summary:\n",
    "In this project, I used a model to predict the result of house racing \n",
    "I used a Python function `parse_past_performance(xml_path)` to extract structured information from the original data. And the extracted information is under the structure of\n",
    "- Horse: name, birth year, origin.\n",
    "  - Trainer and Jockey: last name + first name concatenation.\n",
    "  - Race-specific info: program number, post position, odds.\n",
    "Each row in the resulting DataFrame corresponds to a unique horse entry in a race.\n",
    "Then I used the second function, `parse_results(xml_path)`,  to handle the resultsData XML files by:\n",
    "- Extracting <RACE> and <ENTRY> nodes to access outcome-related data.\n",
    "- Capturing features like:\n",
    "  - Official Finish: the final ranking of the horse.\n",
    "  - Finish Time and Speed Rating: performance measures.\n",
    "  - Dollar Odds: betting market odds at race time.\n",
    "This information provides the ground truth necessary to train supervised models.\n",
    "I used Python’s glob and os modules to:\n",
    "- Locate all relevant .xml files in each dataset folder.\n",
    "- Loop through the files and apply the parsing functions.\n",
    "- Combine all parsed records into large DataFrames for training.\n",
    "This step is essential to scale the project from parsing a few races to processing the entire dataset.\n",
    "While this notebook has not yet executed any predictive modeling, it forms a robust data preprocessing pipeline. It accurately extracts and cleans critical racing information and aligns well with best practices in data engineering for ML.\n",
    "A few important reflections:\n",
    "- Modularity: Functions like parse_past_performance and parse_results are reusable, improving maintainability.\n",
    "- Readability: Despite the use of raw XMLs (which are often difficult to parse), the logic is clearly structured.\n",
    "- Scalability: The use of glob to handle bulk data processing ensures this pipeline can scale to hundreds or thousands of races.\n",
    "Conclusion: This project marks a strong foundation for more advanced work on race outcome prediction and underscores the essential role of data compatibility, especially in high-stakes prediction problems such as horse racing.\n",
    "\n",
    "'''\n",
    "!git clone https://github.com/flyaflya/fsan830spring2025.git\n",
    "%cd fsan830spring2025\n",
    "\n",
    "%cd fsan830spring2025\n",
    "\n",
    "!pip install -U numpy pymc pymc-bart arviz xarray matplotlib scikit-learn\n",
    "\n",
    "import pymc, pymc_bart\n",
    "print(\"pymc version:\", pymc.__version__)\n",
    "print(\"pymc-bart version:\", pymc_bart.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "from pymc_bart import BART\n",
    "from glob import glob\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_past_performance(xml_path):\n",
    "    import xml.etree.ElementTree as ET\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    records = []\n",
    "    for race in root.findall('Race'):\n",
    "        race_number = race.findtext('RaceNumber')\n",
    "        for starters in race.findall('Starters'):\n",
    "            record = {'RaceNumber': race_number}\n",
    "            for item in starters:\n",
    "                if item.tag == 'Horse':\n",
    "                    record['HorseName'] = item.findtext('HorseName')\n",
    "                    record['YearOfBirth'] = item.findtext('YearOfBirth')\n",
    "                    record['FoalingArea'] = item.findtext('FoalingArea')\n",
    "                elif item.tag in ['PostPosition', 'ProgramNumber', 'WeightCarried', 'Odds']:\n",
    "                    record[item.tag] = item.text\n",
    "                elif item.tag == 'Trainer':\n",
    "                    record['Trainer'] = (item.findtext('LastName') or '') + (item.findtext('FirstName') or '')\n",
    "                elif item.tag == 'Jockey':\n",
    "                    record['Jockey'] = (item.findtext('LastName') or '') + (item.findtext('FirstName') or '')\n",
    "            if 'HorseName' in record and record['HorseName']:\n",
    "                for k in record:\n",
    "                    if isinstance(record[k], str):\n",
    "                        record[k] = record[k].strip()\n",
    "                records.append(record)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def parse_results(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    records = []\n",
    "    for race in root.findall('.//RACE'):\n",
    "        race_number = race.get('NUMBER')\n",
    "        for entry in race.findall('ENTRY'):\n",
    "            record = {\n",
    "                'RaceNumber': race_number,\n",
    "                'HorseName': entry.findtext('NAME'),\n",
    "                'OfficialFinish': entry.findtext('OFFICIAL_FIN'),\n",
    "                'FinishTime': entry.findtext('FINISH_TIME'),\n",
    "                'SpeedRating': entry.findtext('SPEED_RATING'),\n",
    "                'DollarOdds': entry.findtext('DOLLAR_ODDS'),\n",
    "            }\n",
    "            for k in record:\n",
    "                if isinstance(record[k], str):\n",
    "                    record[k] = record[k].strip()\n",
    "            records.append(record)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "pp_dir = 'data/rawDataForTraining/pastPerformanceData'\n",
    "res_dir = 'data/rawDataForTraining/resultsData'\n",
    "\n",
    "pp_files = glob(os.path.join(pp_dir, '*.xml'))\n",
    "res_files = glob(os.path.join(res_dir, '*.xml'))\n",
    "\n",
    "print(f\"共发现PastPerformance xml: {len(pp_files)} 份，Result xml: {len(res_files)} 份\")\n",
    "\n",
    "pp_dfs = [parse_past_performance(f) for f in pp_files]\n",
    "res_dfs = [parse_results(f) for f in res_files]\n",
    "\n",
    "df_feat = pd.concat(pp_dfs, ignore_index=True)\n",
    "df_label = pd.concat(res_dfs, ignore_index=True)\n",
    "\n",
    "print(\"特征集 shape:\", df_feat.shape, \"标签集 shape:\", df_label.shape)\n",
    "\n",
    "for df in [df_feat, df_label]:\n",
    "    df['HorseName'] = df['HorseName'].astype(str).str.lower().str.strip()\n",
    "    df['RaceNumber'] = df['RaceNumber'].astype(str).str.strip()\n",
    "\n",
    "df_full = pd.merge(df_feat, df_label, on=['RaceNumber', 'HorseName'], how='inner', suffixes=('_pp', '_res'))\n",
    "print(\"最终训练集 shape:\", df_full.shape)\n",
    "\n",
    "def odds_str_to_float(odds):\n",
    "    if pd.isna(odds):\n",
    "        return None\n",
    "    try:\n",
    "        return float(odds)\n",
    "    except:\n",
    "        if '/' in str(odds):\n",
    "            try:\n",
    "                num, den = odds.split('/')\n",
    "                return float(num) / float(den)\n",
    "            except:\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "df_full['Odds_float'] = df_full['Odds'].apply(odds_str_to_float)\n",
    "df_full['DollarOdds'] = pd.to_numeric(df_full['DollarOdds'], errors='coerce')\n",
    "df_full['OfficialFinish'] = pd.to_numeric(df_full['OfficialFinish'], errors='coerce')\n",
    "df_full['FinishTime'] = pd.to_numeric(df_full['FinishTime'], errors='coerce')\n",
    "df_full['SpeedRating'] = pd.to_numeric(df_full['SpeedRating'], errors='coerce')\n",
    "df_full['WeightCarried'] = pd.to_numeric(df_full['WeightCarried'], errors='coerce')\n",
    "\n",
    "df_full.to_csv('final_supervised_training_set.csv', index=False)\n",
    "print(df_full.head())\n",
    "print(\"可用于建模的特征：\", df_full.columns.tolist())\n",
    "\n",
    "feature_cols = ['Odds_float', 'WeightCarried', 'SpeedRating']  # 你可以增删\n",
    "'''\n",
    "feature_cols = [\n",
    "    'YearOfBirth',\n",
    "    'FoalingArea',\n",
    "    'PostPosition',\n",
    "    'WeightCarried',\n",
    "    'Trainer',\n",
    "    'Jockey',\n",
    "    'SpeedRating',\n",
    "    'Odds_float'\n",
    "]\n",
    "'''\n",
    "X = df_full[feature_cols].fillna(0).values\n",
    "y = df_full['OfficialFinish'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_indices = [\n",
    "    2,    # RaceNumber\n",
    "    44,   # HorseName\n",
    "    45,   # YearOfBirth\n",
    "    56,   # FoalingArea\n",
    "    3,    # PostPosition\n",
    "    42,   # ProgramNumber\n",
    "    50,   # WeightCarried\n",
    "    27,   # Trainer\n",
    "    32,   # Jockey\n",
    "    515,  # Odds (第一场历史比赛的赔率)\n",
    "    615,  # OfficialFinish (第一场历史比赛的名次)\n",
    "    1035, # FinishTime (第一场历史比赛的完赛时间)\n",
    "    845,  # SpeedRating (第一场历史比赛的评分)\n",
    "    43,   # DollarOdds\n",
    "]\n",
    "feature_cols = ['Odds_float', 'WeightCarried', 'SpeedRating']\n",
    "\n",
    "column_indices = [\n",
    "    515,  # Odds\n",
    "    50,   # WeightCarried\n",
    "    845   # SpeedRating\n",
    "]\n",
    "\n",
    "columns = ['Odds', 'WeightCarried', 'SpeedRating']\n",
    "\n",
    "X_test = pd.read_csv('data/rawDataForPrediction/CDX0426.csv', header=None, usecols=column_indices)\n",
    "X_test.columns = columns\n",
    "\n",
    "def odds_str_to_float(s):\n",
    "    try:\n",
    "        if pd.isna(s):\n",
    "            return None\n",
    "        if '-' in str(s):\n",
    "            a, b = str(s).split('-')\n",
    "            return float(a) / float(b)\n",
    "        return float(s)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "X_test['Odds_float'] = X_test['Odds'].apply(odds_str_to_float)\n",
    "\n",
    "X_test_final = X_test[feature_cols]\n",
    "\n",
    "print(X_test_final)\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "    μ = BART(\"μ\", X, y)\n",
    "    σ = pm.HalfNormal(\"σ\", sigma=1.0)\n",
    "    y_obs = pm.Normal(\"y_obs\", mu=μ, sigma=σ, observed=y)\n",
    "    trace = pm.sample(1000, tune=1000, target_accept=0.95, cores=1, random_seed=42)\n",
    "    print(\"模型训练完毕！\")\n",
    "\n",
    "assert μ.name == \"μ\", \"BART 的 name 必须与你 predictions_input 的 key 一致\"\n",
    "\n",
    "import pymc as pm\n",
    "from pymc_bart import BART\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from datetime import datetime\n",
    "\n",
    "X_train = df_full[feature_cols].fillna(0).values\n",
    "y_train = df_full['OfficialFinish'].values\n",
    "\n",
    "with pm.Model() as model:\n",
    "    μ = BART(\"μ\", X_train, y_train)\n",
    "    σ = pm.HalfNormal(\"σ\", sigma=1.0)\n",
    "    y_obs = pm.Normal(\"y_obs\", mu=μ, sigma=σ, observed=y_train)\n",
    "\n",
    "    trace = pm.sample(\n",
    "        1000,\n",
    "        tune=1000,\n",
    "        target_accept=0.95,\n",
    "        cores=1,\n",
    "        random_seed=42,\n",
    "        idata_kwargs={\"log_likelihood\": True}  # ✅ 确保 μ 会被记录进 trace\n",
    "    )\n",
    "\n",
    "print(\"✅ 模型训练完毕！\")\n",
    "\n",
    "μ_train_mean = trace.posterior[\"μ\"].mean(dim=(\"chain\", \"draw\")).values\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_train, μ_train_mean, alpha=0.6)\n",
    "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--')\n",
    "plt.xlabel(\"Actual (Train)\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Training Fit: PyMC-BART\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "r2 = r2_score(y_train, μ_train_mean)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, μ_train_mean))\n",
    "print(f\"训练集 R² Score: {r2:.4f}\")\n",
    "print(f\"训练集 RMSE: {rmse:.2f}\")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def bart_train_and_predict(df_train, df_test_raw, feature_cols, target_col):\n",
    "    X_train = df_train[feature_cols].fillna(0).values\n",
    "    y_train = df_train[target_col].values\n",
    "\n",
    "    X_test = df_test_raw[feature_cols].fillna(0).values\n",
    "    n_test = X_test.shape[0]\n",
    "\n",
    "    X_all = np.vstack([X_train, X_test])\n",
    "    y_all = np.concatenate([y_train, np.zeros(n_test)])\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        μ_all = BART(\"μ\", X_all, y_all)\n",
    "        σ = pm.HalfNormal(\"σ\", sigma=1.0)\n",
    "\n",
    "        y_obs = pm.Normal(\"y_obs\", mu=μ_all[:len(y_train)], sigma=σ, observed=y_train)\n",
    "\n",
    "        y_pred = pm.Normal(\"y_pred\", mu=μ_all[len(y_train):], sigma=σ)\n",
    "\n",
    "        trace = pm.sample(\n",
    "            1000, tune=1000, target_accept=0.95, cores=1, random_seed=42\n",
    "        )\n",
    "\n",
    "        ppc = pm.sample_posterior_predictive(\n",
    "            trace, var_names=[\"y_pred\"], return_inferencedata=False\n",
    "        )\n",
    "\n",
    "    y_pred_dist = ppc[\"y_pred\"]  # shape: (n_chains, n_draws, n_test)\n",
    "    y_pred_dist = y_pred_dist.reshape(-1, y_pred_dist.shape[-1])  # => (n_samples_total, n_test)\n",
    "\n",
    "    if y_pred_dist.shape[1] != n_test:\n",
    "        raise ValueError(f\"预测维度异常: y_pred shape={y_pred_dist.shape}, 预期测试样本数={n_test}\")\n",
    "\n",
    "    y_pred_mean = y_pred_dist.mean(axis=0)\n",
    "    y_pred_std = y_pred_dist.std(axis=0)\n",
    "\n",
    "    results_df = df_test_raw.reset_index(drop=True).copy()\n",
    "    results_df[\"PredictedFinish\"] = y_pred_mean\n",
    "    results_df[\"PredictedStd\"] = y_pred_std\n",
    "    results_df[\"PredictedRank\"] = results_df[\"PredictedFinish\"].rank(method=\"min\").astype(int)\n",
    "\n",
    "    return results_df.sort_values(\"PredictedFinish\").reset_index(drop=True)\n",
    "\n",
    "feature_cols = ['Odds_float', 'WeightCarried', 'SpeedRating']\n",
    "target_col = 'OfficialFinish'\n",
    "\n",
    "results_df_sorted = bart_train_and_predict(df_full, X_test, feature_cols, target_col)\n",
    "\n",
    "print(\"预测完成时间：\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(results_df_sorted.head(10))\n",
    "\n",
    "\n",
    "\n",
    "top5 = results_df_sorted.head(5).copy()\n",
    "top5_labels = [f\"Rank #{i+1}\" for i in range(len(top5))]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.barh(top5_labels, top5[\"PredictedFinish\"], xerr=top5[\"PredictedStd\"])\n",
    "plt.xlabel(\"Predicted Finish\")\n",
    "plt.title(\"Top 5 Predicted Results\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
